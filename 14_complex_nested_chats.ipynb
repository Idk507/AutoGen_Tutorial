{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8253fa2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import autogen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d07bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_list = [\n",
    "    {\n",
    "    }\n",
    "]\n",
    "\n",
    "llm_config = {\n",
    "    \"timeout\": 600,\n",
    "    \"cache_seed\": 42,  # Use 'cache_seed' instead of 'use_cache' (True becomes a seed value)\n",
    "    \"config_list\": config_list,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f120459",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = [\n",
    "    \"\"\"On which days in 2024 was Microsoft Stock higher than $400? Comment on the stock performance.\"\"\",\n",
    "    \"\"\"Make a pleasant joke about it.\"\"\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5747054e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_assitant = autogen.AssistantAgent(\n",
    "    \"Inner Assitant\",\n",
    "    llm_config = llm_config,\n",
    "    is_termination_msg = lambda x : x.get(\"content\",\"\").find(\"TERMINATE\") >=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dca113b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_code_interpretor = autogen.UserProxyAgent(\n",
    "    \"Inner-code interpretor\",\n",
    "    llm_config = llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    code_execution_config={\n",
    "        \"work_dir\":\"coding\",\n",
    "        \"use_docker\":False\n",
    "    },\n",
    "    default_auto_reply = \"\",\n",
    "    is_termination_msg = lambda x: x.get(\"content\", \"\").rstrip().find(\"TERMINATE\") >= 0,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47121f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_chat = autogen.GroupChat(\n",
    "    agents = [inner_assitant,inner_code_interpretor],\n",
    "    messages = [],\n",
    "    max_round = 10,\n",
    "    speaker_selection_method = \"round_robin\",\n",
    "    allow_repeat_speaker = False,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e462cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "manager = autogen.GroupChatManager(\n",
    "    groupchat=group_chat,\n",
    "    is_termination_msg=lambda x: x.get(\"content\", \"\").find(\"TERMINATE\") >= 0,\n",
    "    llm_config=llm_config,\n",
    "    code_execution_config={\n",
    "        \"work_dir\": \"coding\",\n",
    "        \"use_docker\": False,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b5a413",
   "metadata": {},
   "source": [
    "# Inner and outer level individual agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e56c0b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "assitant_1 = autogen.AssistantAgent(\n",
    "    name=\"Assitant_1\",\n",
    "    llm_config=llm_config,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b552bb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant_2 = autogen.AssistantAgent(\n",
    "    name = \"Assitant_2\",\n",
    "    llm_config = llm_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3ed04e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = autogen.AssistantAgent(\n",
    "    name = \"Writer\",\n",
    "    llm_config = llm_config,\n",
    "    system_message = \"You are a professional writer, known for your insightful and engaging articles. You transform complex concepts into clear and concise articles.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ace4ceaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewer = autogen.AssistantAgent(\n",
    "    name=\"Reviewer\",\n",
    "    llm_config={\"config_list\": config_list},\n",
    "    system_message=\"\"\"\n",
    "    You are a compliance reviewer, known for your thoroughness and commitment to standards.\n",
    "    Your task is to scrutinize content for any harmful elements or regulatory violations, ensuring\n",
    "    all materials align with required guidelines.\n",
    "    You must review carefully, identify potential issues, and maintain the integrity of the organization.\n",
    "    Your role demands fairness, a deep understanding of regulations, and a focus on protecting against\n",
    "    harm while upholding a culture of responsibility.\n",
    "    \"\"\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9e9702b",
   "metadata": {},
   "outputs": [],
   "source": [
    "user = autogen.UserProxyAgent(\n",
    "    name=\"User\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda x: x.get(\"content\", \"\").find(\"TERMINATE\") >= 0,\n",
    "    code_execution_config={\n",
    "        \"last_n_messages\": 1,\n",
    "        \"work_dir\": \"tasks\",\n",
    "        \"use_docker\": False,\n",
    "    },  # Please set use_docker=True if docker is available to run the generated code. Using docker is safer than running the generated code directly.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba99e78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def writing_message(recipient, messages, sender, config):\n",
    "    return f\"Polish the content to make an engaging and nicely formatted blog post. \\n\\n {recipient.chat_messages_for_summary(sender)[-1]['content']}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9aa0b4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nested_chat_queue = [\n",
    "    {\"recipient\": manager, \"summary_method\": \"reflection_with_llm\"},\n",
    "    {\"recipient\": writer, \"message\": writing_message, \"summary_method\": \"last_msg\", \"max_turns\": 1},\n",
    "    {\"recipient\": reviewer, \"message\": \"Review the content provided.\", \"summary_method\": \"last_msg\", \"max_turns\": 1},\n",
    "    {\"recipient\": writer, \"message\": writing_message, \"summary_method\": \"last_msg\", \"max_turns\": 1},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9ce28ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "assitant_1.register_nested_chats(\n",
    "    nested_chat_queue,\n",
    "    trigger = user\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9c34a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = user.initiate_chats(\n",
    "    [\n",
    "        {\"recipient\": assitant_1, \"message\": tasks[0], \"max_turns\": 1, \"summary_method\": \"last_msg\"},\n",
    "        {\"recipient\": assistant_2, \"message\": tasks[1]},\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10da6cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "idk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
