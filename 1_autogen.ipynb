{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c8e1664",
   "metadata": {},
   "outputs": [],
   "source": [
    "import autogen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a63513d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AFTER_WORK', 'AfterWork', 'AfterWorkOption', 'Agent', 'AgentNameConflictError', 'AssistantAgent', 'Cache', 'ChatResult', 'ContextExpression', 'ConversableAgent', 'DEFAULT_MODEL', 'FAST_MODEL', 'GroupChat', 'GroupChatManager', 'InvalidCarryOverTypeError', 'LLMConfig', 'ModelClient', 'NoEligibleSpeakerError', 'ON_CONDITION', 'OnCondition', 'OnContextCondition', 'OpenAIWrapper', 'SenderRequiredError', 'SwarmAgent', 'SwarmResult', 'UPDATE_SYSTEM_MESSAGE', 'UndefinedNextAgentError', 'UpdateSystemMessage', 'UserProxyAgent', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '__version__', 'a_initiate_swarm_chat', 'agentchat', 'cache', 'code_utils', 'coding', 'config_list_from_dotenv', 'config_list_from_json', 'config_list_from_models', 'config_list_gpt4_gpt35', 'config_list_openai_aoai', 'doc_utils', 'exception_utils', 'fast_depends', 'filter_config', 'formatting_utils', 'gather_usage_summary', 'get_config_list', 'graph_utils', 'import_utils', 'initiate_chats', 'initiate_swarm_chat', 'io', 'json_utils', 'llm_config', 'logger', 'logging', 'messages', 'oai', 'register_function', 'register_hand_off', 'runtime_logging', 'token_count_utils', 'tools', 'types', 'version']\n",
      "Function: AFTER_WORK\n",
      "Function: AfterWork\n",
      "Function: AfterWorkOption\n",
      "Function: Agent\n",
      "Function: AgentNameConflictError\n",
      "Function: AssistantAgent\n",
      "Function: Cache\n",
      "Function: ChatResult\n",
      "Function: ContextExpression\n",
      "Function: ConversableAgent\n",
      "Function: GroupChat\n",
      "Function: GroupChatManager\n",
      "Function: InvalidCarryOverTypeError\n",
      "Function: LLMConfig\n",
      "Function: ModelClient\n",
      "Function: NoEligibleSpeakerError\n",
      "Function: ON_CONDITION\n",
      "Function: OnCondition\n",
      "Function: OnContextCondition\n",
      "Function: OpenAIWrapper\n",
      "Function: SenderRequiredError\n",
      "Function: SwarmAgent\n",
      "Function: SwarmResult\n",
      "Function: UPDATE_SYSTEM_MESSAGE\n",
      "Function: UndefinedNextAgentError\n",
      "Function: UpdateSystemMessage\n",
      "Function: UserProxyAgent\n",
      "Function: a_initiate_swarm_chat\n",
      "Function: config_list_from_dotenv\n",
      "Function: config_list_from_json\n",
      "Function: config_list_from_models\n",
      "Function: config_list_gpt4_gpt35\n",
      "Function: config_list_openai_aoai\n",
      "Function: filter_config\n",
      "Function: gather_usage_summary\n",
      "Function: get_config_list\n",
      "Function: initiate_chats\n",
      "Function: initiate_swarm_chat\n",
      "Function: register_function\n",
      "Function: register_hand_off\n"
     ]
    }
   ],
   "source": [
    "#list all the modules and functions in the autogen package\n",
    "print(dir(autogen))\n",
    "for name in dir(autogen):\n",
    "    obj = getattr(autogen, name)\n",
    "    if callable(obj):\n",
    "        print(f\"Function: {name}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d83f645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not callable: DEFAULT_MODEL\n",
      "Type: <class 'str'>\n",
      "Value: gpt-4\n",
      "\n",
      "Not callable: FAST_MODEL\n",
      "Type: <class 'str'>\n",
      "Value: gpt-3.5-turbo\n",
      "\n",
      "Not callable: __all__\n",
      "Type: <class 'list'>\n",
      "Value: ['AFTER_WORK', 'DEFAULT_MODEL', 'FAST_MODEL', 'ON_CONDITION', 'UPDATE_SYSTEM_MESSAGE', 'AfterWork', 'AfterWorkOption', 'Agent', 'AgentNameConflictError', 'AssistantAgent', 'Cache', 'ChatResult', 'ContextExpression', 'ConversableAgent', 'GroupChat', 'GroupChatManager', 'InvalidCarryOverTypeError', 'LLMConfig', 'ModelClient', 'NoEligibleSpeakerError', 'OnCondition', 'OnContextCondition', 'OpenAIWrapper', 'SenderRequiredError', 'SwarmAgent', 'SwarmResult', 'UndefinedNextAgentError', 'UpdateSystemMessage', 'UserProxyAgent', '__version__', 'a_initiate_swarm_chat', 'config_list_from_dotenv', 'config_list_from_json', 'config_list_from_models', 'config_list_gpt4_gpt35', 'config_list_openai_aoai', 'filter_config', 'gather_usage_summary', 'get_config_list', 'initiate_chats', 'initiate_swarm_chat', 'register_function', 'register_hand_off']\n",
      "\n",
      "Not callable: __builtins__\n",
      "Type: <class 'dict'>\n",
      "Value: {'__name__': 'builtins', '__doc__': \"Built-in functions, types, exceptions, and other objects.\\n\\nThis module provides direct access to all 'built-in'\\nidentifiers of Python; for example, builtins.len is\\nthe full name for the built-in function len().\\n\\nThis module is not normally accessed explicitly by most\\napplications, but can be useful in modules that provide\\nobjects with the same name as a built-in value, but in\\nwhich the built-in of that name is also needed.\", '__package__': '', '__loader__': <class '_frozen_importlib.BuiltinImporter'>, '__spec__': ModuleSpec(name='builtins', loader=<class '_frozen_importlib.BuiltinImporter'>, origin='built-in'), '__build_class__': <built-in function __build_class__>, '__import__': <built-in function __import__>, 'abs': <built-in function abs>, 'all': <built-in function all>, 'any': <built-in function any>, 'ascii': <built-in function ascii>, 'bin': <built-in function bin>, 'breakpoint': <built-in function breakpoint>, 'callable': <built-in function callable>, 'chr': <built-in function chr>, 'compile': <built-in function compile>, 'delattr': <built-in function delattr>, 'dir': <built-in function dir>, 'divmod': <built-in function divmod>, 'eval': <built-in function eval>, 'exec': <built-in function exec>, 'format': <built-in function format>, 'getattr': <built-in function getattr>, 'globals': <built-in function globals>, 'hasattr': <built-in function hasattr>, 'hash': <built-in function hash>, 'hex': <built-in function hex>, 'id': <built-in function id>, 'input': <bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x00000271F2E3DB50>>, 'isinstance': <built-in function isinstance>, 'issubclass': <built-in function issubclass>, 'iter': <built-in function iter>, 'aiter': <built-in function aiter>, 'len': <built-in function len>, 'locals': <built-in function locals>, 'max': <built-in function max>, 'min': <built-in function min>, 'next': <built-in function next>, 'anext': <built-in function anext>, 'oct': <built-in function oct>, 'ord': <built-in function ord>, 'pow': <built-in function pow>, 'print': <built-in function print>, 'repr': <built-in function repr>, 'round': <built-in function round>, 'setattr': <built-in function setattr>, 'sorted': <built-in function sorted>, 'sum': <built-in function sum>, 'vars': <built-in function vars>, 'None': None, 'Ellipsis': Ellipsis, 'NotImplemented': NotImplemented, 'False': False, 'True': True, 'bool': <class 'bool'>, 'memoryview': <class 'memoryview'>, 'bytearray': <class 'bytearray'>, 'bytes': <class 'bytes'>, 'classmethod': <class 'classmethod'>, 'complex': <class 'complex'>, 'dict': <class 'dict'>, 'enumerate': <class 'enumerate'>, 'filter': <class 'filter'>, 'float': <class 'float'>, 'frozenset': <class 'frozenset'>, 'property': <class 'property'>, 'int': <class 'int'>, 'list': <class 'list'>, 'map': <class 'map'>, 'object': <class 'object'>, 'range': <class 'range'>, 'reversed': <class 'reversed'>, 'set': <class 'set'>, 'slice': <class 'slice'>, 'staticmethod': <class 'staticmethod'>, 'str': <class 'str'>, 'super': <class 'super'>, 'tuple': <class 'tuple'>, 'type': <class 'type'>, 'zip': <class 'zip'>, '__debug__': True, 'BaseException': <class 'BaseException'>, 'BaseExceptionGroup': <class 'BaseExceptionGroup'>, 'Exception': <class 'Exception'>, 'GeneratorExit': <class 'GeneratorExit'>, 'KeyboardInterrupt': <class 'KeyboardInterrupt'>, 'SystemExit': <class 'SystemExit'>, 'ArithmeticError': <class 'ArithmeticError'>, 'AssertionError': <class 'AssertionError'>, 'AttributeError': <class 'AttributeError'>, 'BufferError': <class 'BufferError'>, 'EOFError': <class 'EOFError'>, 'ImportError': <class 'ImportError'>, 'LookupError': <class 'LookupError'>, 'MemoryError': <class 'MemoryError'>, 'NameError': <class 'NameError'>, 'OSError': <class 'OSError'>, 'ReferenceError': <class 'ReferenceError'>, 'RuntimeError': <class 'RuntimeError'>, 'StopAsyncIteration': <class 'StopAsyncIteration'>, 'StopIteration': <class 'StopIteration'>, 'SyntaxError': <class 'SyntaxError'>, 'SystemError': <class 'SystemError'>, 'TypeError': <class 'TypeError'>, 'ValueError': <class 'ValueError'>, 'Warning': <class 'Warning'>, 'FloatingPointError': <class 'FloatingPointError'>, 'OverflowError': <class 'OverflowError'>, 'ZeroDivisionError': <class 'ZeroDivisionError'>, 'BytesWarning': <class 'BytesWarning'>, 'DeprecationWarning': <class 'DeprecationWarning'>, 'EncodingWarning': <class 'EncodingWarning'>, 'FutureWarning': <class 'FutureWarning'>, 'ImportWarning': <class 'ImportWarning'>, 'PendingDeprecationWarning': <class 'PendingDeprecationWarning'>, 'ResourceWarning': <class 'ResourceWarning'>, 'RuntimeWarning': <class 'RuntimeWarning'>, 'SyntaxWarning': <class 'SyntaxWarning'>, 'UnicodeWarning': <class 'UnicodeWarning'>, 'UserWarning': <class 'UserWarning'>, 'BlockingIOError': <class 'BlockingIOError'>, 'ChildProcessError': <class 'ChildProcessError'>, 'ConnectionError': <class 'ConnectionError'>, 'FileExistsError': <class 'FileExistsError'>, 'FileNotFoundError': <class 'FileNotFoundError'>, 'InterruptedError': <class 'InterruptedError'>, 'IsADirectoryError': <class 'IsADirectoryError'>, 'NotADirectoryError': <class 'NotADirectoryError'>, 'PermissionError': <class 'PermissionError'>, 'ProcessLookupError': <class 'ProcessLookupError'>, 'TimeoutError': <class 'TimeoutError'>, 'IndentationError': <class 'IndentationError'>, 'IndexError': <class 'IndexError'>, 'KeyError': <class 'KeyError'>, 'ModuleNotFoundError': <class 'ModuleNotFoundError'>, 'NotImplementedError': <class 'NotImplementedError'>, 'RecursionError': <class 'RecursionError'>, 'UnboundLocalError': <class 'UnboundLocalError'>, 'UnicodeError': <class 'UnicodeError'>, 'BrokenPipeError': <class 'BrokenPipeError'>, 'ConnectionAbortedError': <class 'ConnectionAbortedError'>, 'ConnectionRefusedError': <class 'ConnectionRefusedError'>, 'ConnectionResetError': <class 'ConnectionResetError'>, 'TabError': <class 'TabError'>, 'UnicodeDecodeError': <class 'UnicodeDecodeError'>, 'UnicodeEncodeError': <class 'UnicodeEncodeError'>, 'UnicodeTranslateError': <class 'UnicodeTranslateError'>, 'ExceptionGroup': <class 'ExceptionGroup'>, 'EnvironmentError': <class 'OSError'>, 'IOError': <class 'OSError'>, 'WindowsError': <class 'OSError'>, 'open': <built-in function open>, 'copyright': Copyright (c) 2001-2023 Python Software Foundation.\n",
      "All Rights Reserved.\n",
      "\n",
      "Copyright (c) 2000 BeOpen.com.\n",
      "All Rights Reserved.\n",
      "\n",
      "Copyright (c) 1995-2001 Corporation for National Research Initiatives.\n",
      "All Rights Reserved.\n",
      "\n",
      "Copyright (c) 1991-1995 Stichting Mathematisch Centrum, Amsterdam.\n",
      "All Rights Reserved., 'credits':     Thanks to CWI, CNRI, BeOpen.com, Zope Corporation and a cast of thousands\n",
      "    for supporting Python development.  See www.python.org for more information., 'license': See https://www.python.org/psf/license/, 'help': Type help() for interactive help, or help(object) for help about object., 'execfile': <function execfile at 0x00000271F4455A80>, 'runfile': <function runfile at 0x00000271F45E1A80>, '__IPYTHON__': True, 'display': <function display at 0x00000271F2197B00>, 'get_ipython': <bound method InteractiveShell.get_ipython of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x00000271F4853310>>}\n",
      "\n",
      "Not callable: __cached__\n",
      "Type: <class 'str'>\n",
      "Value: c:\\Users\\dhanu\\miniconda3\\envs\\idk\\Lib\\site-packages\\autogen\\__pycache__\\__init__.cpython-311.pyc\n",
      "\n",
      "Not callable: __doc__\n",
      "Type: <class 'NoneType'>\n",
      "Value: None\n",
      "\n",
      "Not callable: __file__\n",
      "Type: <class 'str'>\n",
      "Value: c:\\Users\\dhanu\\miniconda3\\envs\\idk\\Lib\\site-packages\\autogen\\__init__.py\n",
      "\n",
      "Not callable: __loader__\n",
      "Type: <class '_frozen_importlib_external.SourceFileLoader'>\n",
      "Value: <_frozen_importlib_external.SourceFileLoader object at 0x00000271F491F750>\n",
      "\n",
      "Not callable: __name__\n",
      "Type: <class 'str'>\n",
      "Value: autogen\n",
      "\n",
      "Not callable: __package__\n",
      "Type: <class 'str'>\n",
      "Value: autogen\n",
      "\n",
      "Not callable: __path__\n",
      "Type: <class 'list'>\n",
      "Value: ['c:\\\\Users\\\\dhanu\\\\miniconda3\\\\envs\\\\idk\\\\Lib\\\\site-packages\\\\autogen']\n",
      "\n",
      "Not callable: __spec__\n",
      "Type: <class '_frozen_importlib.ModuleSpec'>\n",
      "Value: ModuleSpec(name='autogen', loader=<_frozen_importlib_external.SourceFileLoader object at 0x00000271F491F750>, origin='c:\\\\Users\\\\dhanu\\\\miniconda3\\\\envs\\\\idk\\\\Lib\\\\site-packages\\\\autogen\\\\__init__.py', submodule_search_locations=['c:\\\\Users\\\\dhanu\\\\miniconda3\\\\envs\\\\idk\\\\Lib\\\\site-packages\\\\autogen'])\n",
      "\n",
      "Not callable: __version__\n",
      "Type: <class 'str'>\n",
      "Value: 0.8.4\n",
      "\n",
      "Not callable: agentchat\n",
      "Type: <class 'module'>\n",
      "Value: <module 'autogen.agentchat' from 'c:\\\\Users\\\\dhanu\\\\miniconda3\\\\envs\\\\idk\\\\Lib\\\\site-packages\\\\autogen\\\\agentchat\\\\__init__.py'>\n",
      "\n",
      "Not callable: cache\n",
      "Type: <class 'module'>\n",
      "Value: <module 'autogen.cache' from 'c:\\\\Users\\\\dhanu\\\\miniconda3\\\\envs\\\\idk\\\\Lib\\\\site-packages\\\\autogen\\\\cache\\\\__init__.py'>\n",
      "\n",
      "Not callable: code_utils\n",
      "Type: <class 'module'>\n",
      "Value: <module 'autogen.code_utils' from 'c:\\\\Users\\\\dhanu\\\\miniconda3\\\\envs\\\\idk\\\\Lib\\\\site-packages\\\\autogen\\\\code_utils.py'>\n",
      "\n",
      "Not callable: coding\n",
      "Type: <class 'module'>\n",
      "Value: <module 'autogen.coding' from 'c:\\\\Users\\\\dhanu\\\\miniconda3\\\\envs\\\\idk\\\\Lib\\\\site-packages\\\\autogen\\\\coding\\\\__init__.py'>\n",
      "\n",
      "Not callable: doc_utils\n",
      "Type: <class 'module'>\n",
      "Value: <module 'autogen.doc_utils' from 'c:\\\\Users\\\\dhanu\\\\miniconda3\\\\envs\\\\idk\\\\Lib\\\\site-packages\\\\autogen\\\\doc_utils.py'>\n",
      "\n",
      "Not callable: exception_utils\n",
      "Type: <class 'module'>\n",
      "Value: <module 'autogen.exception_utils' from 'c:\\\\Users\\\\dhanu\\\\miniconda3\\\\envs\\\\idk\\\\Lib\\\\site-packages\\\\autogen\\\\exception_utils.py'>\n",
      "\n",
      "Not callable: fast_depends\n",
      "Type: <class 'module'>\n",
      "Value: <module 'autogen.fast_depends' from 'c:\\\\Users\\\\dhanu\\\\miniconda3\\\\envs\\\\idk\\\\Lib\\\\site-packages\\\\autogen\\\\fast_depends\\\\__init__.py'>\n",
      "\n",
      "Not callable: formatting_utils\n",
      "Type: <class 'module'>\n",
      "Value: <module 'autogen.formatting_utils' from 'c:\\\\Users\\\\dhanu\\\\miniconda3\\\\envs\\\\idk\\\\Lib\\\\site-packages\\\\autogen\\\\formatting_utils.py'>\n",
      "\n",
      "Not callable: graph_utils\n",
      "Type: <class 'module'>\n",
      "Value: <module 'autogen.graph_utils' from 'c:\\\\Users\\\\dhanu\\\\miniconda3\\\\envs\\\\idk\\\\Lib\\\\site-packages\\\\autogen\\\\graph_utils.py'>\n",
      "\n",
      "Not callable: import_utils\n",
      "Type: <class 'module'>\n",
      "Value: <module 'autogen.import_utils' from 'c:\\\\Users\\\\dhanu\\\\miniconda3\\\\envs\\\\idk\\\\Lib\\\\site-packages\\\\autogen\\\\import_utils.py'>\n",
      "\n",
      "Not callable: io\n",
      "Type: <class 'module'>\n",
      "Value: <module 'autogen.io' from 'c:\\\\Users\\\\dhanu\\\\miniconda3\\\\envs\\\\idk\\\\Lib\\\\site-packages\\\\autogen\\\\io\\\\__init__.py'>\n",
      "\n",
      "Not callable: json_utils\n",
      "Type: <class 'module'>\n",
      "Value: <module 'autogen.json_utils' from 'c:\\\\Users\\\\dhanu\\\\miniconda3\\\\envs\\\\idk\\\\Lib\\\\site-packages\\\\autogen\\\\json_utils.py'>\n",
      "\n",
      "Not callable: llm_config\n",
      "Type: <class 'module'>\n",
      "Value: <module 'autogen.llm_config' from 'c:\\\\Users\\\\dhanu\\\\miniconda3\\\\envs\\\\idk\\\\Lib\\\\site-packages\\\\autogen\\\\llm_config.py'>\n",
      "\n",
      "Not callable: logger\n",
      "Type: <class 'logging.Logger'>\n",
      "Value: <Logger autogen (INFO)>\n",
      "\n",
      "Not callable: logging\n",
      "Type: <class 'module'>\n",
      "Value: <module 'logging' from 'c:\\\\Users\\\\dhanu\\\\miniconda3\\\\envs\\\\idk\\\\Lib\\\\logging\\\\__init__.py'>\n",
      "\n",
      "Not callable: messages\n",
      "Type: <class 'module'>\n",
      "Value: <module 'autogen.messages' from 'c:\\\\Users\\\\dhanu\\\\miniconda3\\\\envs\\\\idk\\\\Lib\\\\site-packages\\\\autogen\\\\messages\\\\__init__.py'>\n",
      "\n",
      "Not callable: oai\n",
      "Type: <class 'module'>\n",
      "Value: <module 'autogen.oai' from 'c:\\\\Users\\\\dhanu\\\\miniconda3\\\\envs\\\\idk\\\\Lib\\\\site-packages\\\\autogen\\\\oai\\\\__init__.py'>\n",
      "\n",
      "Not callable: runtime_logging\n",
      "Type: <class 'module'>\n",
      "Value: <module 'autogen.runtime_logging' from 'c:\\\\Users\\\\dhanu\\\\miniconda3\\\\envs\\\\idk\\\\Lib\\\\site-packages\\\\autogen\\\\runtime_logging.py'>\n",
      "\n",
      "Not callable: token_count_utils\n",
      "Type: <class 'module'>\n",
      "Value: <module 'autogen.token_count_utils' from 'c:\\\\Users\\\\dhanu\\\\miniconda3\\\\envs\\\\idk\\\\Lib\\\\site-packages\\\\autogen\\\\token_count_utils.py'>\n",
      "\n",
      "Not callable: tools\n",
      "Type: <class 'module'>\n",
      "Value: <module 'autogen.tools' from 'c:\\\\Users\\\\dhanu\\\\miniconda3\\\\envs\\\\idk\\\\Lib\\\\site-packages\\\\autogen\\\\tools\\\\__init__.py'>\n",
      "\n",
      "Not callable: types\n",
      "Type: <class 'module'>\n",
      "Value: <module 'autogen.types' from 'c:\\\\Users\\\\dhanu\\\\miniconda3\\\\envs\\\\idk\\\\Lib\\\\site-packages\\\\autogen\\\\types.py'>\n",
      "\n",
      "Not callable: version\n",
      "Type: <class 'module'>\n",
      "Value: <module 'autogen.version' from 'c:\\\\Users\\\\dhanu\\\\miniconda3\\\\envs\\\\idk\\\\Lib\\\\site-packages\\\\autogen\\\\version.py'>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#not callable\n",
    "for name in dir(autogen):\n",
    "    obj = getattr(autogen, name)\n",
    "    if not callable(obj):\n",
    "        print(f\"Not callable: {name}\")\n",
    "        print(f\"Type: {type(obj)}\")\n",
    "        print(f\"Value: {obj}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b806137",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87434545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openai and APITimeoutError are correctly installed and importable.\n",
      "Autogen is correctly installed and importable.\n",
      "Both openai and autogen are installed correctly. You can now use autogen.\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def check_openai_installation():\n",
    "    \"\"\"\n",
    "    Checks if the openai library is installed correctly and attempts to fix common import errors.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Attempt to import the specific module\n",
    "        from openai import APITimeoutError\n",
    "        print(\"openai and APITimeoutError are correctly installed and importable.\")\n",
    "        return True  # Indicate success\n",
    "\n",
    "    except ImportError as e:\n",
    "        print(f\"ImportError: {e}\")\n",
    "        print(\"It seems there is an issue with your openai installation.\")\n",
    "        print(\"I will try to resolve this by reinstalling the openai library.\")\n",
    "\n",
    "        try:\n",
    "            # Uninstall openai\n",
    "            subprocess.check_call([sys.executable, '-m', 'pip', 'uninstall', 'openai', '-y'])\n",
    "            print(\"Successfully uninstalled the previous openai version.\")\n",
    "        except Exception as uninstall_err:\n",
    "            print(f\"Error occurred while uninstalling openai: {uninstall_err}\")\n",
    "            print(\"Please try uninstalling openai manually: pip uninstall openai -y\")\n",
    "            return False\n",
    "\n",
    "        try:\n",
    "            # Install openai, trying both a direct install and an upgrade.\n",
    "            subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'openai', '--upgrade'])\n",
    "            print(\"Successfully reinstalled openai.\")\n",
    "            # Test the import again *after* reinstalling\n",
    "            try:\n",
    "                from openai import APITimeoutError\n",
    "                print(\"Import successful after reinstalling!\")\n",
    "                return True\n",
    "            except ImportError as e2:\n",
    "                print(f\"ImportError after reinstall: {e2}\")\n",
    "                print(\"Reinstallation did not resolve the issue.  There may be a deeper environment problem.\")\n",
    "                return False\n",
    "\n",
    "        except Exception as install_err:\n",
    "            print(f\"Error occurred while installing openai: {install_err}\")\n",
    "            print(\"Please try reinstalling openai manually: pip install openai --upgrade\")\n",
    "            return False\n",
    "    except Exception as general_err:\n",
    "        print(f\"A general error occurred: {general_err}\")\n",
    "        return False\n",
    "\n",
    "def check_autogen_installation():\n",
    "    \"\"\"\n",
    "    Checks if autogen is installed and attempts to fix common import errors.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Attempt to import the specific module\n",
    "        from autogen import ConversableAgent\n",
    "        print(\"Autogen is correctly installed and importable.\")\n",
    "        return True  # Indicate success\n",
    "\n",
    "    except ImportError as e:\n",
    "        print(f\"ImportError: {e}\")\n",
    "        print(\"It seems there is an issue with your autogen installation.\")\n",
    "        print(\"I will try to resolve this by reinstalling autogen.\")\n",
    "\n",
    "        try:\n",
    "            # Uninstall autogen\n",
    "            subprocess.check_call([sys.executable, '-m', 'pip', 'uninstall', 'autogen', '-y'])\n",
    "            print(\"Successfully uninstalled the previous autogen version.\")\n",
    "        except Exception as uninstall_err:\n",
    "            print(f\"Error occurred while uninstalling autogen: {uninstall_err}\")\n",
    "            print(\"Please try uninstalling autogen manually: pip uninstall autogen -y\")\n",
    "            return False\n",
    "\n",
    "        try:\n",
    "            # Install autogen, trying both a direct install and an upgrade.\n",
    "            subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'autogen', '--upgrade'])\n",
    "            print(\"Successfully reinstalled autogen.\")\n",
    "            # Test the import again *after* reinstalling\n",
    "            try:\n",
    "                from autogen import ConversableAgent\n",
    "                print(\"Import successful after reinstalling!\")\n",
    "                return True\n",
    "            except ImportError as e2:\n",
    "                print(f\"ImportError after reinstall: {e2}\")\n",
    "                print(\"Reinstallation did not resolve the issue.  There may be a deeper environment problem.\")\n",
    "                return False\n",
    "\n",
    "        except Exception as install_err:\n",
    "            print(f\"Error occurred while installing autogen: {install_err}\")\n",
    "            print(\"Please try reinstalling autogen manually: pip install autogen --upgrade\")\n",
    "            return False\n",
    "    except Exception as general_err:\n",
    "        print(f\"A general error occurred: {general_err}\")\n",
    "        return False\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    openai_ok = check_openai_installation()\n",
    "    autogen_ok = check_autogen_installation()\n",
    "    if openai_ok and autogen_ok:\n",
    "        print(\"Both openai and autogen are installed correctly. You can now use autogen.\")\n",
    "        #\n",
    "        # import os\n",
    "        # from autogen import ConversableAgent\n",
    "        #\n",
    "        # # Load environment variables (optional, but recommended for storing API keys)\n",
    "        # from dotenv import load_dotenv\n",
    "        #\n",
    "        # load_dotenv()\n",
    "        #\n",
    "        # # Configuration (replace with your actual Azure OpenAI details)\n",
    "        # config_list = [\n",
    "        #     {\n",
    "        #         \"model\": \"your-azure-model-deployment-name\",  # e.g., \"gpt-4\"\n",
    "        #         \"api_key\": os.environ.get(\"AZURE_OPENAI_KEY\"),\n",
    "        #         \"api_base\": \"your-azure-openai-endpoint\",  # e.g., \"https://your-resource-name.openai.azure.com\"\n",
    "        #         \"api_type\": \"azure\",\n",
    "        #         \"api_version\": \"2023-05-15\",  # Or your API version\n",
    "        #     },\n",
    "        # ]\n",
    "        #\n",
    "        # # 1. Create an LLM configuration dictionary\n",
    "        # llm_config = {\n",
    "        #     \"timeout\": 600,  # Increased timeout for longer tasks\n",
    "        #     \"use_cache\": True,\n",
    "        #     \"config_list\": config_list,\n",
    "        # }\n",
    "        #\n",
    "        # # 2. Create the user proxy agent\n",
    "        # user_proxy = autogen.UserProxyAgent(\n",
    "        #     name=\"User_proxy\",\n",
    "        #     system_message=\"\"\"You are a helpful assistant.\n",
    "        #     You will interact with the planner agent to create a plan, and then execute that plan.\n",
    "        #     You can also execute code blocks.\n",
    "        #     \"\"\",\n",
    "        #     code_execution_config={\n",
    "        #         \"work_dir\": \"coding\",  # Directory where code will be executed\n",
    "        #         \"use_docker\": False,  # Set to True if you want to use Docker (requires Docker setup)\n",
    "        #     },\n",
    "        #     human_input_mode=\"NEVER\",  # NEVER, ALWAYS, or TERMINATE.  NEVER means the user does not provide input\n",
    "        # )\n",
    "        #\n",
    "        # # 3. Create the planner agent\n",
    "        # planner = autogen.ConversableAgent(\n",
    "        #     name=\"Planner\",\n",
    "        #     system_message=\"\"\"You are a planner agent.\n",
    "        #     You are responsible for creating a plan to solve the user's problem.\n",
    "        #     First, state the plan.\n",
    "        #     Second, carry out the plan step by step.\n",
    "        #     \"\"\",\n",
    "        #     llm_config=llm_config,\n",
    "        # )\n",
    "        #\n",
    "        # # 4. Create the executor agent\n",
    "        # executor = autogen.ConversableAgent(\n",
    "        #     name=\"Executor\",\n",
    "        #     system_message=\"\"\"You are an executor agent.\n",
    "        #     You are responsible for executing the plan created by the planner.\n",
    "        #     Execute the plan step by step and provide the output.\n",
    "        #     \"\"\",\n",
    "        #     llm_config=llm_config,\n",
    "        #     code_execution_config={\n",
    "        #         \"work_dir\": \"coding\",  # Directory where code will be executed\n",
    "        #         \"use_docker\": False,  # Set to True if you want to use Docker (requires Docker setup)\n",
    "        #     },\n",
    "        # )\n",
    "        # # 5. Create the chief agent, handling the overall flow\n",
    "        # chief_agent = autogen.ConversableAgent(\n",
    "        #     name=\"Chief_Agent\",\n",
    "        #     system_message=\"\"\"You are a chief agent.\n",
    "        #     You are responsible for managing the conversation between the planner and executor.\n",
    "        #     You will initiate the conversation with the planner, and then manage the flow\n",
    "        #     until the goal is achieved.\n",
    "        #     \"\"\",\n",
    "        #     llm_config=llm_config,\n",
    "        # )\n",
    "        #\n",
    "        # # 6. Register the agents.  This is how the chief agent knows about the other agents.\n",
    "        # chief_agent.register_agent(planner)\n",
    "        # chief_agent.register_agent(executor)\n",
    "        #\n",
    "        # # 7. Define the task.  This is what the user wants to achieve.\n",
    "        # task = \"Find the current weather in London and print it to the console.\"\n",
    "        #\n",
    "        # # 8. Start the conversation\n",
    "        # chief_agent.initiate_chat(\n",
    "        #     user_proxy,\n",
    "        #     message=task,\n",
    "        # )\n",
    "    else:\n",
    "        print(\"One or both of openai and autogen installation could not be fixed automatically. Please follow the manual steps.\")\n",
    "        print(\"1. Ensure you are using a compatible Python version (e.g., 3.8, 3.9, 3.10, 3.11).\")\n",
    "        print(\"2. Make sure your pip is up-to-date: `python -m pip install --upgrade pip`\")\n",
    "        print(\"3. Try installing openai again: `pip install openai --upgrade`\")\n",
    "        print(\"4. Try installing autogen again: `pip install autogen --upgrade`\")\n",
    "        print(\"5. If you are using a virtual environment, ensure it is activated.\")\n",
    "        print(\"6. If the problem persists, consider creating a new virtual environment to avoid conflicts.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f9540c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from autogen import ConversableAgent\n",
    "import autogen\n",
    "import tempfile\n",
    "from autogen.coding import LocalCommandLineCodeExecutor\n",
    "from autogen import coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fce2d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_list = [\n",
    " {\n",
    "    }\n",
    "]\n",
    "llm_config = {\n",
    "    \"timeout\": 600,  \n",
    "    \"use_cache\": True,\n",
    "    \"config_list\": config_list,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2018a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "idk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
