{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d9a6720a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "import asyncio\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from autogen_ext.models.azure import AzureAIChatCompletionClient\n",
    "from autogen_core.models import UserMessage\n",
    "from autogen_agentchat.ui import Console \n",
    "from autogen_core.memory import ListMemory,MemoryContent,MemoryMimeType \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f443bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_list = [\n",
    "    {\n",
    "    }\n",
    "]\n",
    "\n",
    "llm_config = {\n",
    "    \"timeout\": 600,\n",
    "    \"cache_seed\": 42,  # Use 'cache_seed' instead of 'use_cache' (True becomes a seed value)\n",
    "    \"config_list\": config_list,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eb84c64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_memory = ListMemory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d07b5642",
   "metadata": {},
   "outputs": [],
   "source": [
    "await user_memory.add(MemoryContent(content=\"The weather should be in metric units\", mime_type=MemoryMimeType.TEXT))\n",
    "\n",
    "await user_memory.add(MemoryContent(content=\"Meal recipe must be vegan\", mime_type=MemoryMimeType.TEXT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "437b0a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_weather(city: str, units: str = \"imperial\") -> str:\n",
    "    if units == \"imperial\":\n",
    "        return f\"The weather in {city} is 73 °F and Sunny.\"\n",
    "    elif units == \"metric\":\n",
    "        return f\"The weather in {city} is 23 °C and Sunny.\"\n",
    "    else:\n",
    "        return f\"Sorry, I don't know the weather in {city}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "328a91b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AzureAIChatCompletionClient Inspection:\n",
      "--------------------------------------------------\n",
      "Class Documentation:\n",
      "\n",
      "    Chat completion client for models hosted on Azure AI Foundry or GitHub Models.\n",
      "    See `here <https://learn.microsoft.com/en-us/azure/ai-studio/reference/reference-model-inference-chat-completions>`_ for more info.\n",
      "\n",
      "    Args:\n",
      "        endpoint (str): The endpoint to use. **Required.**\n",
      "        credential (union, AzureKeyCredential, AsyncTokenCredential): The credentials to use. **Required**\n",
      "        model_info (ModelInfo): The model family and capabilities of the model. **Required.**\n",
      "        model (str): The name of the model. **Required if model is hosted on GitHub Models.**\n",
      "        frequency_penalty: (optional,float)\n",
      "        presence_penalty: (optional,float)\n",
      "        temperature: (optional,float)\n",
      "        top_p: (optional,float)\n",
      "        max_tokens: (optional,int)\n",
      "        response_format: (optional, literal[\"text\", \"json_object\"])\n",
      "        stop: (optional,List[str])\n",
      "        tools: (optional,List[ChatCompletionsToolDefinition])\n",
      "        tool_choice: (optional,Union[str, ChatCompletionsToolChoicePreset, ChatCompletionsNamedToolChoice]])\n",
      "        seed: (optional,int)\n",
      "        model_extras: (optional,Dict[str, Any])\n",
      "\n",
      "    To use this client, you must install the `azure-ai-inference` extension:\n",
      "\n",
      "        .. code-block:: bash\n",
      "\n",
      "            pip install \"autogen-ext[azure]\"\n",
      "\n",
      "    The following code snippet shows how to use the client:\n",
      "\n",
      "        .. code-block:: python\n",
      "\n",
      "            import asyncio\n",
      "            from azure.core.credentials import AzureKeyCredential\n",
      "            from autogen_ext.models.azure import AzureAIChatCompletionClient\n",
      "            from autogen_core.models import UserMessage\n",
      "\n",
      "\n",
      "            async def main():\n",
      "                client = AzureAIChatCompletionClient(\n",
      "                    endpoint=\"endpoint\",\n",
      "                    credential=AzureKeyCredential(\"api_key\"),\n",
      "                    model_info={\n",
      "                        \"json_output\": False,\n",
      "                        \"function_calling\": False,\n",
      "                        \"vision\": False,\n",
      "                        \"family\": \"unknown\",\n",
      "                    },\n",
      "                )\n",
      "\n",
      "                result = await client.create([UserMessage(content=\"What is the capital of France?\", source=\"user\")])\n",
      "                print(result)\n",
      "\n",
      "\n",
      "            if __name__ == \"__main__\":\n",
      "                asyncio.run(main())\n",
      "\n",
      "    \n",
      "--------------------------------------------------\n",
      "Initialization Parameters:\n",
      "mappingproxy(OrderedDict([('self', <Parameter \"self\">),\n",
      "                          ('kwargs',\n",
      "                           <Parameter \"**kwargs: typing_extensions.Unpack[autogen_ext.models.azure.config.AzureAIChatCompletionClientConfig]\">)]))\n",
      "--------------------------------------------------\n",
      "Validation Method:\n",
      "    @staticmethod\n",
      "    def _validate_config(config: Dict[str, Any]) -> AzureAIChatCompletionClientConfig:\n",
      "        if \"endpoint\" not in config:\n",
      "            raise ValueError(\"endpoint is required for AzureAIChatCompletionClient\")\n",
      "        if \"credential\" not in config:\n",
      "            raise ValueError(\"credential is required for AzureAIChatCompletionClient\")\n",
      "        if \"model_info\" not in config:\n",
      "            raise ValueError(\"model_info is required for AzureAIChatCompletionClient\")\n",
      "        validate_model_info(config[\"model_info\"])\n",
      "        if _is_github_model(config[\"endpoint\"]) and \"model\" not in config:\n",
      "            raise ValueError(\"model is required for when using a Github model with AzureAIChatCompletionClient\")\n",
      "        return cast(AzureAIChatCompletionClientConfig, config)\n",
      "\n",
      "--------------------------------------------------\n",
      "Looking for ModelInfo class or validation function:\n",
      "--------------------------------------------------\n",
      "Source file location:\n",
      "Source file: c:\\Users\\dhanu\\miniconda3\\envs\\idk\\Lib\\site-packages\\autogen_ext\\models\\azure\\_azure_ai_client.py\n",
      "--------------------------------------------------\n",
      "Directory Structure:\n",
      "Azure module path: c:\\Users\\dhanu\\miniconda3\\envs\\idk\\Lib\\site-packages\\autogen_ext\\models\\azure\n",
      "Files in directory:\n",
      "  - config\n",
      "  - _azure_ai_client.py\n",
      "  - __init__.py\n",
      "  - __pycache__\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "import importlib\n",
    "import sys\n",
    "from pprint import pprint\n",
    "\n",
    "# Import the necessary library\n",
    "from autogen_ext.models.azure import AzureAIChatCompletionClient\n",
    "\n",
    "# Function to inspect the class and its methods\n",
    "def inspect_azure_client():\n",
    "    print(\"AzureAIChatCompletionClient Inspection:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Get the class documentation\n",
    "    print(\"Class Documentation:\")\n",
    "    print(AzureAIChatCompletionClient.__doc__)\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Get the initialization parameters\n",
    "    print(\"Initialization Parameters:\")\n",
    "    init_signature = inspect.signature(AzureAIChatCompletionClient.__init__)\n",
    "    pprint(init_signature.parameters)\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Try to access the _validate_config method to understand required fields\n",
    "    print(\"Validation Method:\")\n",
    "    try:\n",
    "        validate_method = getattr(AzureAIChatCompletionClient, \"_validate_config\")\n",
    "        print(inspect.getsource(validate_method))\n",
    "    except (AttributeError, TypeError):\n",
    "        print(\"Could not access _validate_config method source code\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Check if there's a ModelInfo class or validation function\n",
    "    print(\"Looking for ModelInfo class or validation function:\")\n",
    "    try:\n",
    "        # Try to import the module that might contain ModelInfo\n",
    "        azure_module = sys.modules.get('autogen_ext.models.azure')\n",
    "        if azure_module:\n",
    "            for name, obj in inspect.getmembers(azure_module):\n",
    "                if name == \"ModelInfo\" or \"model_info\" in name.lower():\n",
    "                    print(f\"Found: {name}\")\n",
    "                    print(inspect.getsource(obj))\n",
    "    except Exception as e:\n",
    "        print(f\"Error looking for ModelInfo: {e}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Try to find the source file\n",
    "    print(\"Source file location:\")\n",
    "    try:\n",
    "        source_file = inspect.getsourcefile(AzureAIChatCompletionClient)\n",
    "        print(f\"Source file: {source_file}\")\n",
    "    except TypeError:\n",
    "        print(\"Could not determine source file\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# Run the inspection\n",
    "inspect_azure_client()\n",
    "\n",
    "# Check the directory structure to find additional modules\n",
    "print(\"Directory Structure:\")\n",
    "try:\n",
    "    azure_path = importlib.import_module('autogen_ext.models.azure').__path__[0]\n",
    "    print(f\"Azure module path: {azure_path}\")\n",
    "    \n",
    "    import os\n",
    "    if os.path.exists(azure_path):\n",
    "        print(\"Files in directory:\")\n",
    "        for file in os.listdir(azure_path):\n",
    "            print(f\"  - {file}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error examining directory structure: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59a3279",
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant_agent = AssistantAgent(\n",
    "    name=\"assistant_agent\",\n",
    "    model_client=AzureAIChatCompletionClient(\n",
    "        model=\"gpt-4o\",\n",
    "        endpoint=\"https://idkrag.openai.azure.com/\",\n",
    "        credential=AzureKeyCredential(\"7WYgbnwGu1U7OoVI2ZUdgAzp9zQ2uLCcpFR5xNCSBIYP9DcwLYRGJQQJ99BEACYeBjFXJ3w3AAABACOGKn3Y\"),\n",
    "        model_info={\n",
    "            \"json_output\": False,\n",
    "            \"function_calling\": True,  \n",
    "            \"vision\": False,\n",
    "            \"family\": \"unknown\",\n",
    "        }\n",
    "    ),\n",
    "    tools=[get_weather],\n",
    "    memory=[user_memory],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde6a1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the agent with a task.\n",
    "stream = assistant_agent.run_stream(task=\"What is the weather in New York?\")\n",
    "await Console(stream)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4aacb67f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[UserMessage(content='What is the weather in New York?', source='user', type='UserMessage')]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await assistant_agent._model_context.get_messages()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82201b77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "idk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
